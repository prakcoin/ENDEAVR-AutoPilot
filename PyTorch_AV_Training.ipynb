{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "YrbytWkwgPr3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUZdaSlLoVfl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acf97944-5434-43ad-8514-058d9036c1ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import torch\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "from torchvision import models, transforms\n",
        "from torchsummary import summary\n",
        "from torchvision.transforms import v2\n",
        "from google.colab import drive\n",
        "from google.colab import runtime\n",
        "from PIL import Image\n",
        "!pip install torchinfo\n",
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "Nsphu-mSgUTM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "File Loading"
      ],
      "metadata": {
        "id": "1FXEJLMk32MI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLHlIwuyKUlH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d65c150-b598-42e0-ebab-5797bf98839d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n",
        "train_front_data = pickle.load(open(\"/content/drive/My Drive/AV Research/train_front_data_80k_256_cropped_color\",'rb'))\n",
        "test_front_data = pickle.load(open(\"/content/drive/My Drive/AV Research/test_front_data_80k_256_cropped_color\",'rb'))\n",
        "\n",
        "output_data = pickle.load(open(\"/content/drive/My Drive/AV Research/train_output_data_80k_256_cropped_color\",'rb'))\n",
        "test_output_data = pickle.load(open(\"/content/drive/My Drive/AV Research/test_output_data_80k_256_cropped_color\",'rb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Transformations"
      ],
      "metadata": {
        "id": "w4r2X4QzIR6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainDataAugmentation(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TrainDataAugmentation, self).__init__()\n",
        "        self.transforms = v2.Compose([\n",
        "            v2.ToImage(),\n",
        "            v2.Grayscale(num_output_channels=1),\n",
        "            v2.RandomAffine(degrees=(0, 30), translate=(0.2, 0.2)),\n",
        "            v2.RandomRotation(degrees=(0, 180)),\n",
        "            v2.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "            v2.ToDtype(torch.float32, scale=True),\n",
        "            v2.Normalize(mean=(0.5437,), std=(0.1366,))\n",
        "        ])\n",
        "\n",
        "    def forward(self, image):\n",
        "        augmented_image = self.transforms(image)\n",
        "        return augmented_image\n",
        "\n",
        "class ValDataAugmentation(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ValDataAugmentation, self).__init__()\n",
        "        self.transforms = v2.Compose([\n",
        "            v2.ToImage(),\n",
        "            v2.Grayscale(num_output_channels=1),\n",
        "            v2.ToDtype(torch.float32, scale=True),\n",
        "            v2.Normalize(mean=(0.5437,), std=(0.1366,))\n",
        "        ])\n",
        "\n",
        "    def forward(self, image):\n",
        "        augmented_image = self.transforms(image)\n",
        "        return augmented_image"
      ],
      "metadata": {
        "id": "QW0DfALbIQ3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing"
      ],
      "metadata": {
        "id": "KukmKhLS35lw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# From: https://stackoverflow.com/questions/60101240/finding-mean-and-standard-deviation-across-image-channels-pytorch\n",
        "def dataset_mean_std(data_loader):\n",
        "  nimages = 0\n",
        "  mean = 0.\n",
        "  std = 0.\n",
        "  for batch, _ in data_loader:\n",
        "      # Rearrange batch to be the shape of [B, C, W * H]\n",
        "      batch = batch.view(batch.size(0), batch.size(3), -1)\n",
        "      # Update total number of images\n",
        "      nimages += batch.size(0)\n",
        "      # Compute mean and std here\n",
        "      mean += batch.float().mean(2).sum(0)\n",
        "      std += batch.float().std(2).sum(0)\n",
        "\n",
        "  # Final step\n",
        "  mean /= nimages\n",
        "  std /= nimages\n",
        "\n",
        "  print(\"Training set mean\", mean)\n",
        "  print(\"Training set std\", std)\n",
        "\n",
        "  return mean, std\n",
        "\n",
        "def show_img(loader):\n",
        "  features, labels = next(iter(loader))\n",
        "  img = features[70].squeeze()\n",
        "  label = labels[70]\n",
        "  plt.imshow(img.T)\n",
        "  plt.show()\n",
        "  print(f\"Label: {label}\")"
      ],
      "metadata": {
        "id": "gq60tLDtXhZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomHorizontalFlipWithSteeringAngle(object):\n",
        "    def __init__(self, p=0.5):\n",
        "        self.p = p\n",
        "\n",
        "    def __call__(self, input, output):\n",
        "        if random.random() < self.p:\n",
        "            v2.functional.hflip(input)\n",
        "            output[0] = -output[0]\n",
        "        return input, output\n",
        "\n",
        "\n",
        "class AVDataset(Dataset):\n",
        "    def __init__(self, input_images, output_values, transform):\n",
        "        self.input_images = input_images\n",
        "        self.output_values = output_values\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.output_values)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_image = self.input_images[idx]\n",
        "        output_value = self.output_values[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            input_image = self.transform(input_image)\n",
        "            input_image, output_value = RandomHorizontalFlipWithSteeringAngle(0.5)(input_image, output_value)\n",
        "\n",
        "        return input_image, output_value\n",
        "\n",
        "train_data_augmentation = TrainDataAugmentation()\n",
        "val_data_augmentation = ValDataAugmentation()\n",
        "\n",
        "train_dataset = AVDataset(input_images=train_front_data, output_values=output_data, transform=train_data_augmentation)\n",
        "val_dataset = AVDataset(input_images=test_front_data, output_values=test_output_data, transform=val_data_augmentation)\n",
        "\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=1, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=1, pin_memory=True)\n",
        "del train_dataset, val_dataset, train_front_data, test_front_data, output_data, test_output_data"
      ],
      "metadata": {
        "id": "rh9E4Bl9y7NK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "zgO93M8CgaYf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural Network"
      ],
      "metadata": {
        "id": "C4TO-9zj6Yg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# From: https://github.com/wzlxjtu/PositionalEncoding2D\n",
        "class PositionalEncoding2d(nn.Module):\n",
        "    def __init__(self, d_model, height, width):\n",
        "        super(PositionalEncoding2d, self).__init__()\n",
        "        if d_model % 4 != 0:\n",
        "            raise ValueError(\"Cannot use sin/cos positional encoding with \"\n",
        "                            \"odd dimension (got dim={:d})\".format(d_model))\n",
        "        pe = torch.zeros(d_model, height, width)\n",
        "        # Each dimension use half of d_model\n",
        "        d_model = int(d_model / 2)\n",
        "        div_term = torch.exp(torch.arange(0., d_model, 2) *\n",
        "                            -(math.log(10000.0) / d_model))\n",
        "        pos_w = torch.arange(0., width).unsqueeze(1)\n",
        "        pos_h = torch.arange(0., height).unsqueeze(1)\n",
        "        pe[0:d_model:2, :, :] = torch.sin(pos_w * div_term).transpose(0, 1).unsqueeze(1).repeat(1, height, 1)\n",
        "        pe[1:d_model:2, :, :] = torch.cos(pos_w * div_term).transpose(0, 1).unsqueeze(1).repeat(1, height, 1)\n",
        "        pe[d_model::2, :, :] = torch.sin(pos_h * div_term).transpose(0, 1).unsqueeze(2).repeat(1, 1, width)\n",
        "        pe[d_model + 1::2, :, :] = torch.cos(pos_h * div_term).transpose(0, 1).unsqueeze(2).repeat(1, 1, width)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe"
      ],
      "metadata": {
        "id": "JedyQe5Y7YxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspired by: https://github.com/reshalfahsi/separableconv-torch\n",
        "class SeparableConv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias):\n",
        "        super(SeparableConv2d, self).__init__()\n",
        "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=in_channels, bias=bias)\n",
        "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.depthwise(x)\n",
        "        x = self.pointwise(x)\n",
        "        return x\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, num_layers: int, pool: bool, short: bool):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.pooling = pool\n",
        "        self.short = short\n",
        "\n",
        "        self.inconv = nn.Sequential(\n",
        "            SeparableConv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=1, padding=1, bias=False),\n",
        "            nn.SELU()\n",
        "        )\n",
        "\n",
        "        layers = []\n",
        "        for _ in range(num_layers - 1):\n",
        "            layers.append(SeparableConv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size, stride=1, padding=1, bias=False))\n",
        "            layers.append(nn.SELU())\n",
        "        self.convlayers = nn.Sequential(*layers)\n",
        "\n",
        "        if self.pooling:\n",
        "            self.pool = nn.MaxPool2d(kernel_size=kernel_size, stride=2, padding=1)\n",
        "            self.shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2, bias=False)\n",
        "        else:\n",
        "            self.shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
        "\n",
        "        self.sact = nn.SELU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.inconv(x)\n",
        "        out = self.convlayers(out)\n",
        "\n",
        "        if self.pooling:\n",
        "            out = self.pool(out)\n",
        "\n",
        "        if self.short:\n",
        "            shortcut = self.shortcut(x)\n",
        "            out = out + shortcut\n",
        "            out = self.sact(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "UjmmoyAK6ykn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AVModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AVModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.act = nn.SELU()\n",
        "        self.positional_encoding = PositionalEncoding2d(64, 171, 256)\n",
        "\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            ResidualBlock(in_channels=64, out_channels=64, kernel_size=3, num_layers=4, pool=True, short=True),\n",
        "            ResidualBlock(in_channels=64, out_channels=128, kernel_size=3, num_layers=4, pool=True, short=True),\n",
        "            ResidualBlock(in_channels=128, out_channels=256, kernel_size=3, num_layers=4, pool=True, short=True),\n",
        "            ResidualBlock(in_channels=256, out_channels=512, kernel_size=3, num_layers=4, pool=True, short=True),\n",
        "        )\n",
        "\n",
        "        self.attention = nn.MultiheadAttention(embed_dim=176, num_heads=8, dropout=0.5, batch_first=True)\n",
        "\n",
        "        self.dense_layers = nn.Sequential(\n",
        "            nn.Linear(512, 1024, bias=False),\n",
        "            nn.SELU(),\n",
        "            nn.Linear(1024, 1024, bias=False),\n",
        "            nn.SELU(),\n",
        "            nn.Linear(1024, 1024, bias=False),\n",
        "            nn.SELU(),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "\n",
        "        self.output_layer = nn.Linear(1024, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.act(x)\n",
        "        x = F.layer_norm(self.positional_encoding(x), x.shape)\n",
        "        x = self.conv_layers(x)\n",
        "\n",
        "        batch_size, channels, height, width = x.size()\n",
        "        x = x.view(batch_size, channels, height * width)\n",
        "        attention_output, _ = self.attention(x, x, x)\n",
        "        x = F.layer_norm(x + attention_output, x.shape)\n",
        "\n",
        "        x = torch.mean(x.view(x.size(0), x.size(1), -1), dim=2) # GlobalAveragePooling2D\n",
        "        x = self.dense_layers(x)\n",
        "        x = self.output_layer(x)\n",
        "\n",
        "        steering_output = F.hardtanh(x[:, 0:1])\n",
        "        throttle_brake_output = F.hardtanh(x[:, 1:], min_val=0)\n",
        "        out = torch.cat((steering_output, throttle_brake_output), dim=1)\n",
        "        return out"
      ],
      "metadata": {
        "id": "zUuj3NlUqT8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Util"
      ],
      "metadata": {
        "id": "LREHs7j-gdqz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MFPE Loss"
      ],
      "metadata": {
        "id": "XYEmoiqDz8dT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MFPELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MFPELoss, self).__init__()\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        error = input - target\n",
        "        fourth_power_error = error ** 4\n",
        "        mean_fourth_power_error = torch.mean(fourth_power_error)\n",
        "        return mean_fourth_power_error"
      ],
      "metadata": {
        "id": "oVX2aCc4z70O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Early Stopping"
      ],
      "metadata": {
        "id": "UsbecnRmgzW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=1, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.min_validation_loss = float('inf')\n",
        "\n",
        "    def early_stop(self, validation_loss):\n",
        "        if validation_loss < self.min_validation_loss:\n",
        "            self.min_validation_loss = validation_loss\n",
        "            self.counter = 0\n",
        "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                return True\n",
        "        return False"
      ],
      "metadata": {
        "id": "WKuvJUubgyq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autoclip"
      ],
      "metadata": {
        "id": "oxlaJSitQjPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# From: https://github.com/pseeth/autoclip/blob/master/autoclip.py\n",
        "class AutoClip:\n",
        "    def __init__(self, percentile):\n",
        "        self.grad_history = []\n",
        "        self.percentile = percentile\n",
        "\n",
        "    def compute_grad_norm(self, model):\n",
        "        total_norm = 0\n",
        "        for p in model.parameters():\n",
        "            if p.grad is not None:\n",
        "                param_norm = p.grad.data.norm(2)\n",
        "                total_norm += param_norm.item() ** 2\n",
        "        total_norm = total_norm ** (1. / 2)\n",
        "\n",
        "        return total_norm\n",
        "\n",
        "    def __call__(self, model):\n",
        "        grad_norm = self.compute_grad_norm(model)\n",
        "        self.grad_history.append(grad_norm)\n",
        "        clip_value = np.percentile(self.grad_history, self.percentile)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)"
      ],
      "metadata": {
        "id": "TA8lkOyLQiWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loop"
      ],
      "metadata": {
        "id": "pBGSiDEygoLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model = AVModel().to(device)\n",
        "num_epochs = 50\n",
        "learning_rate = 0.00001\n",
        "criterion = MFPELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "early_stopping = EarlyStopping(patience=3)\n",
        "\n",
        "torch.autograd.set_detect_anomaly(False)\n",
        "torch.backends.cudnn.benchmark = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "autoclipper = AutoClip(percentile=10)\n",
        "\n",
        "print(summary(model, input_size=(batch_size, 1, 171, 256)))\n",
        "\n",
        "def train_loop(train_loader, model, criterion, optimizer, device):\n",
        "    size = len(train_loader.dataset)\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    num_batches = len(train_loader)\n",
        "\n",
        "    # Training loop\n",
        "    for batch, (inputs, targets) in enumerate(tqdm(train_loader)):\n",
        "        optimizer.zero_grad()\n",
        "        inputs = inputs.float().to(device)\n",
        "        targets = targets.float().to(device)\n",
        "        with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, targets)\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        scaler.scale(loss).backward()\n",
        "        autoclipper(model)\n",
        "\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * batch_size + len(inputs)\n",
        "            print(f\"Training loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "    train_loss = train_loss / num_batches\n",
        "    return train_loss\n",
        "\n",
        "def val_loop(val_loader, model, criterion, device):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    num_batches = len(val_loader)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in val_loader:\n",
        "            inputs = inputs.float().to(device, non_blocking=True)\n",
        "            targets = targets.float().to(device, non_blocking=True)\n",
        "            outputs = model(inputs)\n",
        "            val_loss += criterion(outputs, targets).item()\n",
        "\n",
        "    val_loss = val_loss / num_batches\n",
        "    return val_loss\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "    train_loss = train_loop(train_loader, model, criterion, optimizer, device)\n",
        "    val_loss = val_loop(val_loader, model, criterion, device)\n",
        "    print(f\"Train loss: {train_loss:>8f} - Val loss: {val_loss:>8f} \\n\")\n",
        "    if early_stopping.early_stop(val_loss):\n",
        "        print(f\"Early stopping after {epoch+1} epochs \\n\")\n",
        "        print(f\"Best val loss: {early_stopping.min_validation_loss} \\n\")\n",
        "        break"
      ],
      "metadata": {
        "id": "vWJ-gDVwIEpy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "014f0ae3-dafc-43e0-f45b-07060240deaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===============================================================================================\n",
            "Layer (type:depth-idx)                        Output Shape              Param #\n",
            "===============================================================================================\n",
            "AVModel                                       [128, 3]                  --\n",
            "├─Conv2d: 1-1                                 [128, 64, 171, 256]       576\n",
            "├─SELU: 1-2                                   [128, 64, 171, 256]       --\n",
            "├─PositionalEncoding2d: 1-3                   [128, 64, 171, 256]       --\n",
            "├─Sequential: 1-4                             [128, 512, 11, 16]        --\n",
            "│    └─ResidualBlock: 2-1                     [128, 64, 86, 128]        --\n",
            "│    │    └─Sequential: 3-1                   [128, 64, 171, 256]       4,672\n",
            "│    │    └─Sequential: 3-2                   [128, 64, 171, 256]       14,016\n",
            "│    │    └─MaxPool2d: 3-3                    [128, 64, 86, 128]        --\n",
            "│    │    └─Conv2d: 3-4                       [128, 64, 86, 128]        4,096\n",
            "│    │    └─SELU: 3-5                         [128, 64, 86, 128]        --\n",
            "│    └─ResidualBlock: 2-2                     [128, 128, 43, 64]        --\n",
            "│    │    └─Sequential: 3-6                   [128, 128, 86, 128]       8,768\n",
            "│    │    └─Sequential: 3-7                   [128, 128, 86, 128]       52,608\n",
            "│    │    └─MaxPool2d: 3-8                    [128, 128, 43, 64]        --\n",
            "│    │    └─Conv2d: 3-9                       [128, 128, 43, 64]        8,192\n",
            "│    │    └─SELU: 3-10                        [128, 128, 43, 64]        --\n",
            "│    └─ResidualBlock: 2-3                     [128, 256, 22, 32]        --\n",
            "│    │    └─Sequential: 3-11                  [128, 256, 43, 64]        33,920\n",
            "│    │    └─Sequential: 3-12                  [128, 256, 43, 64]        203,520\n",
            "│    │    └─MaxPool2d: 3-13                   [128, 256, 22, 32]        --\n",
            "│    │    └─Conv2d: 3-14                      [128, 256, 22, 32]        32,768\n",
            "│    │    └─SELU: 3-15                        [128, 256, 22, 32]        --\n",
            "│    └─ResidualBlock: 2-4                     [128, 512, 11, 16]        --\n",
            "│    │    └─Sequential: 3-16                  [128, 512, 22, 32]        133,376\n",
            "│    │    └─Sequential: 3-17                  [128, 512, 22, 32]        800,256\n",
            "│    │    └─MaxPool2d: 3-18                   [128, 512, 11, 16]        --\n",
            "│    │    └─Conv2d: 3-19                      [128, 512, 11, 16]        131,072\n",
            "│    │    └─SELU: 3-20                        [128, 512, 11, 16]        --\n",
            "├─MultiheadAttention: 1-5                     [128, 512, 176]           124,608\n",
            "├─Sequential: 1-6                             [128, 1024]               --\n",
            "│    └─Linear: 2-5                            [128, 1024]               524,288\n",
            "│    └─SELU: 2-6                              [128, 1024]               --\n",
            "│    └─Linear: 2-7                            [128, 1024]               1,048,576\n",
            "│    └─SELU: 2-8                              [128, 1024]               --\n",
            "│    └─Linear: 2-9                            [128, 1024]               1,048,576\n",
            "│    └─SELU: 2-10                             [128, 1024]               --\n",
            "│    └─Dropout: 2-11                          [128, 1024]               --\n",
            "├─Linear: 1-7                                 [128, 3]                  3,075\n",
            "===============================================================================================\n",
            "Total params: 4,176,963\n",
            "Trainable params: 4,176,963\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (G): 377.09\n",
            "===============================================================================================\n",
            "Input size (MB): 22.41\n",
            "Forward/backward pass size (MB): 46182.44\n",
            "Params size (MB): 16.21\n",
            "Estimated Total Size (MB): 46221.06\n",
            "===============================================================================================\n",
            "Epoch 1\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/625 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "  0%|          | 1/625 [00:10<1:52:58, 10.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.123673  [  128/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 101/625 [03:35<17:54,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.010814  [12928/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 201/625 [07:00<14:29,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.004182  [25728/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 301/625 [10:25<11:04,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.063306  [38528/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 401/625 [13:50<07:39,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.013785  [51328/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 501/625 [17:15<04:14,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.028335  [64128/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 601/625 [20:40<00:49,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.072845  [76928/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [21:29<00:00,  2.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.048502 - Val loss: 0.025264 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/625 [00:02<29:23,  2.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.038063  [  128/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 101/625 [03:28<17:56,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.007250  [12928/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 201/625 [06:53<14:31,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.002970  [25728/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 301/625 [10:19<11:05,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.066907  [38528/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 401/625 [13:44<07:40,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.012815  [51328/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 501/625 [17:10<04:14,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.023119  [64128/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 601/625 [20:35<00:49,  2.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.032667  [76928/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [21:25<00:00,  2.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.040115 - Val loss: 0.025216 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/625 [00:02<29:25,  2.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.040887  [  128/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 101/625 [03:28<17:56,  2.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.008815  [12928/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 201/625 [06:53<14:31,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.003057  [25728/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 301/625 [10:19<11:05,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.054825  [38528/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 401/625 [13:44<07:40,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.012686  [51328/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 501/625 [17:10<04:14,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.021046  [64128/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 601/625 [20:35<00:49,  2.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.029863  [76928/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [21:25<00:00,  2.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.037136 - Val loss: 0.026138 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/625 [00:02<29:14,  2.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.039149  [  128/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 101/625 [03:28<17:56,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.013129  [12928/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 201/625 [06:53<14:31,  2.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.004478  [25728/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 301/625 [10:19<11:05,  2.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.049832  [38528/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 401/625 [13:44<07:40,  2.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.011052  [51328/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 501/625 [17:10<04:14,  2.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.018290  [64128/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 601/625 [20:35<00:49,  2.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.027291  [76928/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [21:25<00:00,  2.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.034216 - Val loss: 0.028801 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/625 [00:02<29:31,  2.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.039552  [  128/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 101/625 [03:28<17:56,  2.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.018531  [12928/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 201/625 [06:53<14:31,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.002902  [25728/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 301/625 [10:19<11:05,  2.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.048477  [38528/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 401/625 [13:44<07:40,  2.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.012001  [51328/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 501/625 [17:10<04:14,  2.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.016658  [64128/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 601/625 [20:35<00:49,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.024397  [76928/80000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [21:25<00:00,  2.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.033283 - Val loss: 0.030582 \n",
            "\n",
            "Early stopping after 5 epochs \n",
            "\n",
            "Best val loss: 0.025216350458562374 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"/content/drive/My Drive/AV Research/summer_torch_model256.pt\")"
      ],
      "metadata": {
        "id": "FB5eHj7vR9zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "smfexEVEXIGg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}